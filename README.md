# Goal Selection Strategies for Learning Goal-Oriented Value Functions

**Degree:** COMS

**Description:** Recent work in compositional reinforcement learning has demonstrated how to
combine skills to solve tasks specified using Boolean algebra operators. However, the algorithm
to do so uses standard Q-learning with epsilon greedy exploration. One aspect of the algorithm
is the way the agent decides on which goal to explore, which is currently done in a greedy
fashion. In this project, we propose extending this algorithm to incorporate different ways of goal
selection, such as through uniform random or bandit-based strategies. This project also involves
the creation of a virtual environment in Unity or mujoco-worldgen.

**Tags/topics:** Reinforcement learning, deep reinforcement learning, game design

**References:** 
1. [Tasse, Geraud Nangue, Steven James, and Benjamin Rosman. A Boolean Task Algebra for Reinforcement Learning. Neurips 2020.](https://proceedings.neurips.cc/paper/2020/hash/6ba3af5d7b2790e73f0de32e5c8c1798-Abstract.html)
2. [Benureau, Fabien, and Pierre-Yves Oudeyer. "Diversity-driven selection of exploration strategies in multi-armed bandits." In 2015 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob), pp. 135-142. IEEE, 2015.](https://ieeexplore.ieee.org/abstract/document/7346130)
3. [Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.](https://books.google.com/books?hl=en&lr=&id=uWV0DwAAQBAJ&oi=fnd&pg=PR7&dq=+Reinforcement+learning:+An+introduction&ots=mirNs6X4i8&sig=Gh6KgbbNms8_OGtnKEmgvRtExck)
